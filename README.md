# JobScraper - Backend de Scraping y GestiÃ³n de Ofertas Laborales

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

## ğŸ“‹ DescripciÃ³n

JobScraper es un backend robusto desarrollado en Python usando FastAPI para el scraping automatizado y gestiÃ³n inteligente de ofertas laborales. El sistema permite extraer ofertas de trabajo de mÃºltiples sitios web, procesarlas, almacenarlas en una base de datos y proporcionar una API REST completa para su consulta y gestiÃ³n.

## âœ¨ CaracterÃ­sticas Principales

- ğŸš€ **API REST Completa**: Endpoints optimizados para gestionar ofertas laborales
- ğŸ•·ï¸ **Scraping Inteligente**: ExtracciÃ³n automatizada de mÃºltiples sitios web de empleo
- ğŸ’¾ **Base de Datos Robusta**: Almacenamiento persistente con SQLAlchemy y PostgreSQL
- âœ… **ValidaciÃ³n de Datos**: Esquemas Pydantic para validaciÃ³n y serializaciÃ³n
- ğŸ§ª **Testing Completo**: Suite de pruebas unitarias y de integraciÃ³n
- ğŸ”§ **Scripts de Mantenimiento**: Utilidades para migraciÃ³n y administraciÃ³n
- ğŸ“Š **Logging Avanzado**: Sistema de logs estructurado para monitoreo
- ğŸ”’ **ConfiguraciÃ³n Segura**: GestiÃ³n de variables de entorno y secretos

## ğŸ—ï¸ Arquitectura del Proyecto

```
jobscraper/
â”œâ”€â”€ ğŸ“ app/
â”‚   â”œâ”€â”€ ğŸŒ api/              # Endpoints y rutas de la API REST
â”‚   â”œâ”€â”€ ğŸ•·ï¸ scraper/          # MÃ³dulos de scraping web
â”‚   â”œâ”€â”€ ğŸ“Š models/           # Modelos de datos y esquemas Pydantic
â”‚   â”œâ”€â”€ ğŸ—„ï¸ database/         # ConfiguraciÃ³n y operaciones de BD
â”‚   â”œâ”€â”€ âš™ï¸ core/             # Funcionalidades centrales y utilidades
â”‚   â””â”€â”€ ğŸš€ main.py           # Punto de entrada de la aplicaciÃ³n
â”œâ”€â”€ ğŸ§ª tests/               # Pruebas unitarias y de integraciÃ³n
â”œâ”€â”€ ğŸ“œ scripts/             # Scripts de mantenimiento y migraciÃ³n
â”œâ”€â”€ âš™ï¸ config.py            # ConfiguraciÃ³n global del proyecto
â”œâ”€â”€ ğŸ“‹ requirements.txt     # Dependencias del proyecto
â””â”€â”€ ğŸ“– README.md           # DocumentaciÃ³n principal
```

## ğŸš€ Inicio RÃ¡pido

### Prerrequisitos

- Python 3.8 o superior
- PostgreSQL (opcional, se puede usar SQLite para desarrollo)
- Git

### InstalaciÃ³n

1. **Clonar el repositorio**
   ```bash
   git clone https://github.com/tu-usuario/jobscraper.git
   cd jobscraper
   ```

2. **Crear y activar entorno virtual**
   ```bash
   # Linux/Mac
   python -m venv venv
   source venv/bin/activate
   
   # Windows
   python -m venv venv
   venv\Scripts\activate
   ```

3. **Instalar dependencias**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configurar variables de entorno**
   ```bash
   cp .env.example .env
   # Editar .env con tus configuraciones
   ```

5. **Ejecutar migraciones de base de datos**
   ```bash
   python jobmatcher/scripts/migrate_db.py
   ```

## ğŸ¯ Uso

### Ejecutar el servidor de desarrollo

```bash
uvicorn jobscraper.app.main:app --reload --host 0.0.0.0 --port 8000
```

La API estarÃ¡ disponible en: `http://localhost:8000`

### DocumentaciÃ³n interactiva

- **Swagger UI**: `http://localhost:8000/docs`
- **ReDoc**: `http://localhost:8000/redoc`

### Ejecutar scrapers

```bash
# Ejecutar scraper especÃ­fico
python jobscraper/scripts/run_scraper.py --site linkedin

# Ejecutar todos los scrapers
python jobscraper/scripts/run_scraper.py --all
```

## ğŸ”§ ConfiguraciÃ³n

### Variables de Entorno

Crear un archivo `.env` en la raÃ­z del proyecto:

```env
# Base de datos
DATABASE_URL=postgresql://usuario:password@localhost/jobscraper
# o para desarrollo local
DATABASE_URL=sqlite:///./jobscraper.db

# API Configuration
API_V1_STR=/api/v1
PROJECT_NAME=JobScraper
DEBUG=True

# Scraping Configuration
SCRAPING_DELAY=1
MAX_CONCURRENT_REQUESTS=10
USER_AGENT=JobScraper-Bot/1.0

# Security
SECRET_KEY=tu-clave-secreta-muy-segura
ACCESS_TOKEN_EXPIRE_MINUTES=30
```

## ğŸ“¡ API Endpoints

### Ofertas Laborales

- `GET /api/v1/jobs` - Listar ofertas con filtros
- `GET /api/v1/jobs/{job_id}` - Obtener detalle de oferta
- `POST /api/v1/jobs` - Crear nueva oferta
- `PUT /api/v1/jobs/{job_id}` - Actualizar oferta
- `DELETE /api/v1/jobs/{job_id}` - Eliminar oferta

### Empresas

- `GET /api/v1/companies` - Listar empresas
- `GET /api/v1/companies/{company_id}` - Detalle de empresa

### Scraping

- `POST /api/v1/scrape/start` - Iniciar proceso de scraping
- `GET /api/v1/scrape/status` - Estado del scraping
- `GET /api/v1/scrape/stats` - EstadÃ­sticas de scraping

## ğŸ§ª Testing

```bash
# Ejecutar todas las pruebas
pytest

# Ejecutar con cobertura
pytest --cov=jobscraper

# Ejecutar pruebas especÃ­ficas
pytest jobscraper/tests/test_api.py
```

## ğŸ› ï¸ Scripts de Mantenimiento

```bash
# Migrar base de datos
python jobscraper/scripts/migrate_db.py

# Ejecutar scraping programado
python jobscraper/scripts/run_scraper.py

# Limpiar datos duplicados
python jobmatcher/scripts/clean_duplicates.py
```

## ğŸ“Š Monitoreo y Logs

Los logs se almacenan en la carpeta `logs/` con rotaciÃ³n automÃ¡tica:

- `logs/app.log` - Logs generales de la aplicaciÃ³n
- `logs/scraper.log` - Logs especÃ­ficos de scraping
- `logs/error.log` - Logs de errores

## ğŸ¤ ContribuciÃ³n

Â¡Las contribuciones son bienvenidas! Por favor:

1. **Fork** el proyecto
2. **Crear** una rama para tu feature (`git checkout -b feature/nueva-funcionalidad`)
3. **Commit** tus cambios (`git commit -am 'Agregar nueva funcionalidad'`)
4. **Push** a la rama (`git push origin feature/nueva-funcionalidad`)
5. **Crear** un Pull Request

### GuÃ­as de ContribuciÃ³n

- Seguir PEP 8 para el estilo de cÃ³digo
- Escribir tests para nuevas funcionalidades
- Actualizar documentaciÃ³n cuando sea necesario
- Usar commits descriptivos

## ğŸ“ Roadmap

- [ ] IntegraciÃ³n con mÃ¡s sitios de empleo
- [ ] Sistema de notificaciones
- [ ] API de matching inteligente
- [ ] Dashboard web
- [ ] IntegraciÃ³n con redes sociales
- [ ] AnÃ¡lisis de tendencias del mercado laboral

## ğŸ› Reportar Bugs

Si encuentras un bug, por favor crea un issue con:

- DescripciÃ³n detallada del problema
- Pasos para reproducir
- Comportamiento esperado vs actual
- InformaciÃ³n del entorno (OS, Python version, etc.)

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

## ğŸ‘¥ Autores

- **Tu Nombre** - *Desarrollo inicial* - [@tu-usuario](https://github.com/tu-usuario)

## ğŸ™ Agradecimientos

- FastAPI por el excelente framework
- SQLAlchemy por el ORM robusto
- Scrapy por las herramientas de scraping
- La comunidad de Python por las librerÃ­as increÃ­bles

---

â­ **Â¡Si este proyecto te resulta Ãºtil, no olvides darle una estrella!** â­
